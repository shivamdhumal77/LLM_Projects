{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOn8gZgKFVDDbS+H9HJTy1G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivamdhumal77/LLM_Projects/blob/main/rag_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain_openai pandas langchain_community faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjXfT5KbPvVo",
        "outputId": "2a303466-be3f-4cb1-c4a3-3ca0671663b2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDxVN5D8i6bz",
        "outputId": "2863de0b-0b9a-4e74-ad96-aa10a6394e8a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# 1. Load and preprocess CSV data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Convert and format date\n",
        "    df['Date'] = pd.to_datetime(df['Date'], utc=True).dt.tz_convert(None)\n",
        "    df['Date'] = df['Date'].dt.strftime('%d-%m-%Y')  # Format: day-month-year\n",
        "\n",
        "    # Create text data with proper formatting\n",
        "    text_data = []\n",
        "    for _, row in df.iterrows():\n",
        "        entry = f\"Date: {row['Date']}\"\n",
        "\n",
        "        # Conditionally add other columns if they exist\n",
        "        if 'Open' in row and pd.notna(row['Open']):\n",
        "            entry += f\", Open: {row['Open']}\"\n",
        "        if 'High' in row and pd.notna(row['High']):\n",
        "            entry += f\", High: {row['High']}\"\n",
        "        if 'Low' in row and pd.notna(row['Low']):\n",
        "            entry += f\", Low: {row['Low']}\"\n",
        "        if 'Close' in row and pd.notna(row['Close']):\n",
        "            entry += f\", Close: {row['Close']}\"\n",
        "        if 'Volume' in row and pd.notna(row['Volume']):\n",
        "            entry += f\", Volume: {row['Volume']}\"\n",
        "\n",
        "        text_data.append(entry)\n",
        "\n",
        "    # Combine all text into a single document for proper chunking\n",
        "    full_text = \"\\n\".join(text_data)\n",
        "    return df, full_text\n",
        "\n",
        "# 2. Process and split documents\n",
        "def process_documents(full_text):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=100,\n",
        "        separator=\"\\n\"\n",
        "    )\n",
        "    return text_splitter.split_text(full_text)\n",
        "\n",
        "# 3. Create vector store\n",
        "def create_vector_store(docs):\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"  # Fixed model name\n",
        "    )\n",
        "    return FAISS.from_texts(docs, embeddings)\n",
        "\n",
        "# 4. Set up QA chain\n",
        "def setup_qa_chain(vector_store):\n",
        "    # Initialize ChatOpenAI model\n",
        "    llm_1 = ChatOpenAI(\n",
        "        api_key=\"ollama\",\n",
        "        base_url=\"https://sunny-gerri-finsocialdigitalsystem-d9b385fa.koyeb.app/v1\",\n",
        "        model=\"athene-v2\"\n",
        "    )\n",
        "\n",
        "    # Custom prompt template\n",
        "    prompt_template = \"\"\"Use the following financial data to answer the question:\n",
        "    {context}\n",
        "\n",
        "    Question: {question}\n",
        "    Answer:\"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(\n",
        "        template=prompt_template,\n",
        "        input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    return RetrievalQA.from_chain_type(\n",
        "        llm=llm_1,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=vector_store.as_retriever(),\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "\n",
        "# Normalize query to match date format (dd-mm-yyyy)\n",
        "def normalize_date_query(query):\n",
        "    # Search for date pattern in query (e.g., 2 Feb 2023 or 02-02-2023)\n",
        "    date_pattern = r\"(\\d{1,2})\\s*(\\w{3})\\s*(\\d{4})\"  # e.g. \"2 Feb 2023\"\n",
        "    match = re.search(date_pattern, query.lower())\n",
        "    if match:\n",
        "        day = match.group(1).zfill(2)  # Ensure 2 digits\n",
        "        month_str = match.group(2).title()\n",
        "        year = match.group(3)\n",
        "        # Convert month name to number\n",
        "        month_number = datetime.strptime(month_str, \"%b\").month\n",
        "        formatted_date = f\"{day}-{month_number:02d}-{year}\"\n",
        "        return formatted_date\n",
        "    return query  # Return as is if no date pattern found\n",
        "\n",
        "# Main execution flow\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    df, data_text = load_and_preprocess_data(\"/content/AAPL_historical_data.csv\")  # Replace with your CSV path\n",
        "\n",
        "    # Process documents\n",
        "    documents = process_documents(data_text)\n",
        "\n",
        "    # Create vector store\n",
        "    vector_store = create_vector_store(documents)\n",
        "\n",
        "    # Setup QA chain\n",
        "    qa_chain = setup_qa_chain(vector_store)\n",
        "\n",
        "    # Query example\n",
        "    query = \"give me the details on 3 feb 2023\"  # Example query\n",
        "    normalized_query = normalize_date_query(query)\n",
        "\n",
        "    # Check if the date exists in the data\n",
        "    if normalized_query in df['Date'].values:\n",
        "        row_data = df[df['Date'] == normalized_query].iloc[0]\n",
        "        answer = f\"Date: {row_data['Date']}, Open: {row_data['Open']}, High: {row_data['High']}, Low: {row_data['Low']}, Close: {row_data['Close']}, Volume: {row_data['Volume']}\"\n",
        "    else:\n",
        "        response = qa_chain.invoke({\"query\": query})\n",
        "        answer = response[\"result\"]  # Fallback to vector store if exact date not found\n",
        "\n",
        "    print(\"Question:\", query)\n",
        "    print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzAkI6nwas7v",
        "outputId": "d6a312f2-1079-442f-97d3-e33acb21efa1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: give me the details on 3 feb 2023\n",
            "Answer: Date: 03-02-2023, Open: 146.4895254643634, High: 155.74223078414798, Low: 146.29160978319123, Close: 152.89219665527344, Volume: 154357300\n"
          ]
        }
      ]
    }
  ]
}